{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSSxSiUCyEze",
        "outputId": "1bfb604a-5760-4991-b951-aab0cf4fe726"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae0k2aOeygNe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Input, Lambda\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Adagrad, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.metrics import binary_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.models import Model\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import PIL\n",
        "import cv2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rajs-7o5ygQF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the paths to your data folders\n",
        "train_data_dir = '/content/drive/MyDrive/CLL_Train_More'\n",
        "test_data_dir = '/content/drive/MyDrive/CLL_Test'\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_and_preprocess_data(data_dir):\n",
        "    # Initialize empty lists to store images and labels\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate through the images in the directory\n",
        "    for img_name in os.listdir(data_dir):\n",
        "        # Read the image\n",
        "        img = cv2.imread(os.path.join(data_dir, img_name))\n",
        "        # Preprocess the image (e.g., resize, normalize)\n",
        "        img = cv2.resize(img, (224, 224))  # Resize to fit your model's input size\n",
        "        img = img.astype('float32') / 255.0  # Normalize pixel values to [0, 1]\n",
        "        # Append the preprocessed image to the list\n",
        "        images.append(img)\n",
        "        # Append the label (1 for tumor)\n",
        "        labels.append(1)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load and preprocess training data\n",
        "train_images, train_labels = load_and_preprocess_data(train_data_dir)\n",
        "\n",
        "# Load and preprocess test data\n",
        "test_images, test_labels = load_and_preprocess_data(test_data_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gll9-xF-ygS8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class PatchDataGenerator(Sequence):\n",
        "    def __init__(self, data_dir, patch_size, stride, batch_size):\n",
        "        self.data_dir = data_dir\n",
        "        self.patch_size = patch_size\n",
        "        self.stride = stride\n",
        "        self.batch_size = batch_size\n",
        "        self.image_paths = [os.path.join(data_dir, fname) for fname in os.listdir(data_dir)]\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_paths) * (512 // self.patch_size) ** 2 / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_image_paths = self.image_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        X, y = self.__data_generation(batch_image_paths)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.image_paths)\n",
        "\n",
        "    def __data_generation(self, batch_image_paths):\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for img_path in batch_image_paths:\n",
        "            img = cv2.imread(img_path)\n",
        "            img = img.astype('float32') / 255.0\n",
        "            patches = extract_patches(img, self.patch_size, self.stride)\n",
        "            images.extend(patches)\n",
        "            labels.extend([1] * len(patches))  # Assuming all images contain tumor\n",
        "\n",
        "        return np.array(images), np.array(labels)\n",
        "\n",
        "def extract_patches(image, patch_size, stride):\n",
        "    patches = []\n",
        "    h, w, _ = image.shape\n",
        "    for i in range(0, h - patch_size + 1, stride):\n",
        "        for j in range(0, w - patch_size + 1, stride):\n",
        "            patch = image[i:i + patch_size, j:j + patch_size]\n",
        "            patches.append(patch)\n",
        "    return np.array(patches)\n",
        "\n",
        "# Parameters\n",
        "patch_size = 16\n",
        "stride = 16\n",
        "batch_size = 16  # Start with a smaller batch size\n",
        "\n",
        "# Create data generators\n",
        "train_generator = PatchDataGenerator(train_data_dir, patch_size, stride, batch_size)\n",
        "test_generator = PatchDataGenerator(test_data_dir, patch_size, stride, batch_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xh52Fx5ygVk",
        "outputId": "134b0517-9918-46b1-9cd3-795f4a40708e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14780481 (56.38 MB)\n",
            "Trainable params: 14780481 (56.38 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.optimizers import Adagrad\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "\n",
        "def create_deep_mil_model(input_shape):\n",
        "    base = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    #for layer in base.layers:\n",
        "     #   layer.trainable = False\n",
        "\n",
        "\n",
        "    x = base.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Create an instance of the Adagrad optimizer with the desired learning rate\n",
        "    optimizer = Adagrad(learning_rate=0.00002)\n",
        "\n",
        "    # Compile the model with the custom optimizer\n",
        "    model = Model(inputs=base.input, outputs=x)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Update the input shape to match the size of your image patches\n",
        "input_shape = (224, 224, 3)  # Patch size\n",
        "deep_mil_model = create_deep_mil_model(input_shape)\n",
        "deep_mil_model.summary()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOdqnKeOygYE",
        "outputId": "b46ad6b2-657f-47de-cc1b-22d5e34dc05d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "94/94 [==============================] - 44s 295ms/step - loss: 0.2797 - accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "94/94 [==============================] - 19s 205ms/step - loss: 0.1825 - accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "94/94 [==============================] - 20s 210ms/step - loss: 0.1278 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Train the Deep MIL model\n",
        "history = deep_mil_model.fit(train_images, train_labels, epochs=3, batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFizblq8ygak",
        "outputId": "079217d6-3c1c-4aef-a502-386380ebf78e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 11s 5s/step - loss: 0.1069 - accuracy: 1.0000\n",
            "Test Loss: 0.10692152380943298\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = deep_mil_model.evaluate(test_images, test_labels)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQbCTLn-LhRC",
        "outputId": "3209c62d-4dcf-4004-9631-5e661bbfcc9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Save the trained model to a file\n",
        "deep_mil_model.save('/content/drive/MyDrive/trained_model_CLL.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dNLNsOjyuck",
        "outputId": "5cf01143-010f-40cb-b3a6-f7640900b728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Image 1 - Tumor Confidence: 90.85%\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Image 2 - Tumor Confidence: 87.07%\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Image 3 - Tumor Confidence: 90.83%\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Image 4 - Tumor Confidence: 90.47%\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Image 5 - Tumor Confidence: 91.15%\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Image 6 - Tumor Confidence: 90.75%\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Image 7 - Tumor Confidence: 89.31%\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Image 8 - Tumor Confidence: 89.33%\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Image 9 - Tumor Confidence: 90.73%\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Image 10 - Tumor Confidence: 88.78%\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Image 11 - Tumor Confidence: 90.73%\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Image 12 - Tumor Confidence: 90.67%\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Image 13 - Tumor Confidence: 89.78%\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Image 14 - Tumor Confidence: 90.01%\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Image 15 - Tumor Confidence: 90.30%\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Image 16 - Tumor Confidence: 88.80%\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Image 17 - Tumor Confidence: 89.44%\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Image 18 - Tumor Confidence: 90.87%\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Image 19 - Tumor Confidence: 89.22%\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Image 20 - Tumor Confidence: 88.80%\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Image 21 - Tumor Confidence: 89.77%\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Image 22 - Tumor Confidence: 89.99%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 23 - Tumor Confidence: 90.29%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 24 - Tumor Confidence: 90.33%\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Image 25 - Tumor Confidence: 87.87%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 26 - Tumor Confidence: 90.93%\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Image 27 - Tumor Confidence: 90.76%\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Image 28 - Tumor Confidence: 87.59%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 29 - Tumor Confidence: 89.05%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 30 - Tumor Confidence: 89.95%\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Image 31 - Tumor Confidence: 90.35%\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Image 32 - Tumor Confidence: 90.46%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 33 - Tumor Confidence: 89.54%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 34 - Tumor Confidence: 90.74%\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Image 35 - Tumor Confidence: 91.42%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 36 - Tumor Confidence: 89.53%\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Image 37 - Tumor Confidence: 89.85%\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Image 38 - Tumor Confidence: 89.59%\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Image 39 - Tumor Confidence: 91.11%\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Image 40 - Tumor Confidence: 89.58%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 41 - Tumor Confidence: 89.29%\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Image 42 - Tumor Confidence: 90.03%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 43 - Tumor Confidence: 89.94%\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Image 44 - Tumor Confidence: 90.48%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 45 - Tumor Confidence: 89.23%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 46 - Tumor Confidence: 90.00%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 47 - Tumor Confidence: 88.69%\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Image 48 - Tumor Confidence: 89.36%\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Image 49 - Tumor Confidence: 89.82%\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Image 50 - Tumor Confidence: 89.78%\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(test_images)):\n",
        "    image = np.expand_dims(test_images[i], axis=0)\n",
        "    confidence = deep_mil_model.predict(image)[0][0]\n",
        "    print(f'Image {i + 1} - Tumor Confidence: {confidence * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TESTING THE MIL"
      ],
      "metadata": {
        "id": "0fmZw88dFi4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the trained model\n",
        "model_path = '/content/drive/MyDrive/trained_model_CLL.h5'\n",
        "trained_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    # Load and preprocess the test image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = img.astype('float32') / 255.0\n",
        "    return img\n",
        "\n",
        "def generate_heatmap(model, image):\n",
        "    # Generate the heatmap for the test image\n",
        "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer('block5_conv3').output, model.output])\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(image)\n",
        "        top_pred_index = tf.argmax(predictions[0])\n",
        "        top_class_channel = predictions[:, top_pred_index]\n",
        "\n",
        "    grads = tape.gradient(top_class_channel, conv_outputs)[0]\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
        "\n",
        "    conv_outputs = conv_outputs[0].numpy()\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        conv_outputs[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    heatmap = np.mean(conv_outputs, axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "\n",
        "    return heatmap, predictions[0][top_pred_index] * 100  # Extracting tumor confidence\n",
        "\n",
        "# Path to the new external test image\n",
        "test_image_path = '/content/drive/MyDrive/MIL_CLL_TEST/30.png'\n",
        "\n",
        "# Preprocess the test image\n",
        "test_image = preprocess_image(test_image_path)\n",
        "\n",
        "# Generate the heatmap for the test image\n",
        "heatmap, tumor_confidence = generate_heatmap(trained_model, np.expand_dims(test_image, axis=0))\n",
        "\n",
        "# Adjust the brightness of the heatmap\n",
        "heatmap = cv2.resize(heatmap, (test_image.shape[1], test_image.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap * 0.5)  # Adjust brightness by multiplying by 0.5\n",
        "\n",
        "# Display the original test image and the heatmap\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(test_image)\n",
        "plt.title('Original Test Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(heatmap, cmap='jet')\n",
        "plt.title('Heatmap - Tumor Confidence: {:.2f}%'.format(tumor_confidence))\n",
        "plt.colorbar()\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ekKJGcPnFlK2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}